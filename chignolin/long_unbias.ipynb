{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "In this notebook I analyze all the data collected through the iterations for the reinforcement TICA "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb=0.008314\n",
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'temp':340, \n",
    "    'beta': 1./(340*kb),\n",
    "    'kbt': None,\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :10,\n",
    "}\n",
    "#--------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set = \"long_unbias/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "data = load_dataframe(set+\"COLVAR\") \n",
    "descriptors_names = data.filter(regex='^dd_[^a-z]').columns.values\n",
    "#rmsd_ca end hbonds\n",
    "data.plot.scatter(y=\"rmsd_ca\",x=\"end\",ax=ax)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"long simulation\")\n",
    "ax.set_ylabel(\"rmsd_ca\")\n",
    "ax.set_xlabel(\"end\")\n",
    "#fig.savefig(root+\"images/traj_bias\"+str(k)+\".png\",dpi=300,facecolor=\"white\",transparent=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "data = load_dataframe(set+\"COLVAR\") \n",
    "descriptors_names = data.filter(regex='^dd_[^a-z]').columns.values\n",
    "#rmsd_ca end hbonds\n",
    "data.plot.scatter(y=\"hbonds\",x=\"end\",ax=ax)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"long simulation\")\n",
    "ax.set_ylabel(\"hbonds\")\n",
    "ax.set_xlabel(\"end\")\n",
    "#fig.savefig(root+\"images/traj_bias\"+str(k)+\".png\",dpi=300,facecolor=\"white\",transparent=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "data = load_dataframe(set+\"COLVAR\") \n",
    "descriptors_names = data.filter(regex='^dd_[^a-z]').columns.values\n",
    "#rmsd_ca end hbonds\n",
    "data.plot.scatter(y=\"rmsd_ca\",x=\"hbonds\",ax=ax)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_title(\"long simulation\")\n",
    "ax.set_ylabel(\"rmsd_ca\")\n",
    "ax.set_xlabel(\"hbonds\")\n",
    "#fig.savefig(root+\"images/traj_bias\"+str(k)+\".png\",dpi=300,facecolor=\"white\",transparent=False)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,axs = plt.subplots(1,3,figsize=(14,4))\n",
    "data = load_dataframe(set+\"COLVAR\")\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",ax=axs[0])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",ax=axs[1])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"long simulation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FES estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#-- estimation of Free Energy Surface --#\n",
    "X = data[descriptors_names].to_numpy()\n",
    "s = data[[\"rmsd_ca\",\"hbonds\"]].to_numpy()\n",
    "logweight=np.zeros(len(data))\n",
    "gridspec_fes(s,logweight,sim_parameters)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep-TICA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lag,max_lag = 20,5 #0.2,20\n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "train_sim = 1 # number of previous simulations to train the NN\n",
    "shuffle = False # if shuffle the data between batches\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "data = load_dataframe(set+\"COLVAR\")\n",
    "print(data.head())\n",
    "size = len(data)\n",
    "descriptors_names = data.filter(regex='^dd[^a-z]').columns.values\n",
    "print(descriptors_names)\n",
    "print( len(descriptors_names) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 5\n",
    "n_input = len(descriptors_names) # can change..\n",
    "train_parameters = {\n",
    "              'descriptors': '^dd[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,256,256,n_output],#[n_input,60,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':400,\n",
    "              'batchsize': -1, #---> Ã¨ da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "\n",
    "print(\"layers: \",train_parameters[\"nodes\"])\n",
    "# how many data in single batch, batchsize\n",
    "n_train = int( size*train_parameters[\"trainsize\"] )\n",
    "n_valid = int( size*(1-train_parameters[\"trainsize\"])-int(10*max_lag) )\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=lag,interval=[0,n_train+n_valid])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "# to not divide the set, it create a dataset composed by all the found couples with different lag times\n",
    "#print(n*n_train)\n",
    "#print(len(ConcatDataset(train_datasets)))\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')\n",
    "#-- export checkpoint (for loading the model back to python) and torchscript traced module --#\n",
    "save_folder = set+\"deeptica/\"\n",
    "try:\n",
    "    os.mkdir(save_folder)\n",
    "except:\n",
    "    print(\"already exists\")\n",
    "#-- move to cpu before saving results --#\n",
    "model.to(\"cpu\")\n",
    "model.export(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[descriptors_names].to_numpy()\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,4),sharey=True)\n",
    "data.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"b\")\n",
    "data.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(14,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",c=\"cv1\",cmap=\"fessa\",ax=axs[0])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",c=\"cv1\",cmap=\"fessa\",ax=axs[1])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",c=\"cv1\",cmap=\"fessa\",ax=axs[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig,axs = plt.subplots(1,3,figsize=(14,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",c=\"cv2\",cmap=\"fessa\",ax=axs[0])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",c=\"cv2\",cmap=\"fessa\",ax=axs[1])#, color=color[k])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",c=\"cv2\",cmap=\"fessa\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"long simulation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",C=\"cv1\",cmap=\"fessa\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"unbias simulation, cv1\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",C=\"cv1\",cmap=\"fessa\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",C=\"cv1\",cmap=\"fessa\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",C=\"cv2\",cmap=\"fessa\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"unbias simulation, cv2\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",C=\"cv2\",cmap=\"fessa\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",C=\"cv2\",cmap=\"fessa\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = data.filter(regex=\"^cv\").to_numpy()\n",
    "logweight=np.zeros(s.shape[0])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        temp=sim_parameters[\"temp\"],\n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\",\"F(cv2) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(cv1,cv2)$\")\n",
    "ax.set_ylabel(\"FES [Kj/mol]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_parameters[\"plot_max_fes\"] = 40\n",
    "s = data.filter(regex=\"^cv\").to_numpy()[::1]\n",
    "logweight=np.zeros(len(s))\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "#-- 2D plot --#\n",
    "fes,grid,bounds,error = compute_fes(s, weights=np.exp(logweight),\n",
    "                                    temp=sim_parameters[\"temp\"],\n",
    "                                    kbt=sim_parameters[\"kbt\"],\n",
    "                                    blocks=sim_parameters[\"blocks\"],\n",
    "                                    bandwidth=sim_parameters[\"bandwidth\"],scale_by='range'\n",
    "                                    ,plot=True, ax = ax,plot_max_fes=sim_parameters[\"plot_max_fes\"])\n",
    "\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Deep-TICA 2\")\n",
    "ax.set_ylabel(\"Deep-TICA 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('mlcvs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "34f06b9f9681e9a7231f3100f6e351611d3f9f188d680707206d70c247429f78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
