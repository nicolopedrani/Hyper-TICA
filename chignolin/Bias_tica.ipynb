{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "Starting from the basin B it is possible to escape from the local minima within 5ns  \n",
    "While starting from basin A it is possible to escape within 155 ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb=0.008314\n",
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'temp':340, \n",
    "    'beta': 1./(340*kb),\n",
    "    'kbt': None,\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :30,\n",
    "}\n",
    "#--------------------------------------#\n",
    "print(kb*340)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arguments for deep tica cvs\n",
    "ARG = \"\"\n",
    "count =0\n",
    "descriptors_file = \"plumed-descriptors.dat\" # \"plumed-descriptors.dat\", \"plumed-driver.dat\"\n",
    "file = open('script/'+descriptors_file, 'r').readlines() # all descriptors\n",
    "#file = open('script/plumed-descriptors.dat', 'r').readlines() # most important descriptors from Luigi's article, it is not correct a priori\n",
    "for line in file:\n",
    "    if count > 6:\n",
    "        #print(line)\n",
    "        if line == \"\\n\":\n",
    "            break\n",
    "        ARG+=line.split()[0][:-1]\n",
    "        ARG+=\",\"\n",
    "    count+=1\n",
    "\n",
    "Time = 10\n",
    "STRIDE = 100\n",
    "BARRIER=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with unbias simulation\n",
    "folder = \"unbias/bias1_tica/\"\n",
    "\n",
    "print(\"###--- Start Simulations ---###\")\n",
    "#-- run gromacs --#\n",
    "execute(\"cp script/* \"+folder,folder=\".\")\n",
    "execute(\"sed -i '0,/ns/s/ns.*/ns=\"+str(Time)+\"/' run_gromacs.sh\",folder=folder)\n",
    "#execute(\"./run_gromacs.sh\",folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^dd_[^a-z]').columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.scatter(y=\"rmsd_ca\",x=\"end\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"biased tica simulation\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.scatter(y=\"rmsd_ca\",x=\"hbonds\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.scatter(y=\"hbonds\",x=\"end\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",ax=axs[0])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",ax=axs[1])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"biased tica simulation\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1,figsize=(14,10))#,sharey=True)\n",
    "\n",
    "#-- in ps --#\n",
    "last=1000\n",
    "x = np.linspace(0,last+1,last)\n",
    "acorr = np.empty(last)\n",
    "timescale = np.empty(len(descriptors_names))\n",
    "k=0\n",
    "for desc in descriptors_names:\n",
    "    #print(\"autocorrelation for \", desc)\n",
    "    for i in range(last):\n",
    "        acorr[i] = data[desc].autocorr(i)\n",
    "    axs[0].plot(x,acorr)\n",
    "    timescale[k] = integrate.trapz(acorr[:last],x[:last])\n",
    "    k+=1\n",
    "\n",
    "times = pd.DataFrame(descriptors_names,columns=[\"descriptors\"])\n",
    "times[\"timescale\"] = timescale\n",
    "times.plot(kind=\"bar\",x=\"descriptors\",y=\"timescale\",rot=45,ax=axs[1],fontsize=5,label=r\"$\\xi$\")\n",
    "\n",
    "axs[0].set_xlabel(r'$\\tau$')\n",
    "axs[0].set_title(r'$C(\\tau)$')\n",
    "axs[1].set_title(r'$\\xi=\\int d\\tau C(\\tau)$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(np.max(timescale))\n",
    "print(np.min(timescale))\n",
    "\n",
    "#fit_timeacorr(descriptors_names,data,axs=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepTICA Analysis and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lag,max_lag = 0.2,5 \n",
    "n = 5 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "shuffle = False # if shuffle the data between batches\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "descriptors_names = data.filter(regex='^dd[^a-z]').columns.values\n",
    "\n",
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 5 # 2 non linear combination of the descriptors  \n",
    "n_input = len(descriptors_names) # can change..\n",
    "train_parameters = {\n",
    "              'descriptors': '^dd[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,60,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':600,\n",
    "              'batchsize': -1, #---> Ã¨ da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "\n",
    "# how many data in single batch, batchsize\n",
    "n_train = int( len(data)*train_parameters[\"trainsize\"] )\n",
    "n_valid = int( len(data)*(1-train_parameters[\"trainsize\"])-int(10*max_lag) )\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=np.round(lag,3),interval=[0,n_train+n_valid])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')\n",
    "\n",
    "#-- export checkpoint (for loading the model back to python) and torchscript traced module --#\n",
    "save_folder = folder+\"deeptica/\"\n",
    "try:\n",
    "    os.mkdir(save_folder)\n",
    "except:\n",
    "    print(\"already exists\")\n",
    "#-- move to cpu before saving results --#\n",
    "model.to(\"cpu\")\n",
    "model.export(save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding to data the cvs values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "data.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"b\")\n",
    "data.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the correlation (*Pearson* correlation ,which simply means normed correlation) of the Deep-TICA cvs with the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(2,1,figsize=(16,12),sharex=True)\n",
    "for k,cv in enumerate([\"cv1\",\"cv2\"]):\n",
    "    cols = [cv]\n",
    "    cols.extend(data.filter(regex=train_parameters[\"descriptors\"]).columns)\n",
    "    corr = data[cols].corr(method='pearson')\n",
    "    corr[cv].drop(cv).plot(kind='bar', ax=axs[k], rot=45, color=\"b\",fontsize=5,label=r\"$C(deep|desc)$\")\n",
    "    axs[k].set_title('Correlation with DeepTICA '+str(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(18,6))\n",
    "times[\"timescale\"] = times[\"timescale\"]/np.max(times[\"timescale\"])\n",
    "cols = [\"cv1\"]\n",
    "cols.extend(data.filter(regex=train_parameters[\"descriptors\"]).columns)\n",
    "corr = data[cols].corr(method='pearson')\n",
    "times[\"corr\"] = np.abs(corr[\"cv1\"].to_numpy()[1:])\n",
    "times.plot(kind=\"bar\",x=\"descriptors\",rot=45,ax=ax,fontsize=5,stacked=False)\n",
    "ax.set_title(r'Correlation with DeepTICA 1 vs $\\xi$')\n",
    "ax.legend([r\"$\\frac{\\xi}{max(\\xi)}$\",r\"$|C(deep|desc)|$\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FES estimate from cvs  \n",
    "Obviously from this first simulation it is not possible to found a cvs that from data are able to distinguish all the possible basins. I recall that our approach is a **data drive approach**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = data.filter(regex=\"^cv\").to_numpy()\n",
    "logweight=data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        temp=sim_parameters[\"temp\"],\n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\",\"F(cv2) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(cv1,cv2)$\")\n",
    "ax.set_ylabel(\"FES [Kj/mol]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolines  \n",
    "We can use the data obtained from **angles** folder, biasing both $\\psi$ and $\\phi$ angles, to plot the isolines of the new Cvs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",cmap=\"fessa\",C=\"cv1\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"biased tica simulation, cv1\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",cmap=\"fessa\",C=\"cv1\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",cmap=\"fessa\",C=\"cv1\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",C=\"cv2\",cmap=\"fessa\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"biased tica cv2\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",C=\"cv2\",cmap=\"fessa\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",C=\"cv2\",cmap=\"fessa\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",c=\"cv1\",cmap=\"fessa\",ax=axs[0])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",c=\"cv1\",cmap=\"fessa\",ax=axs[1])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",c=\"cv1\",cmap=\"fessa\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"biased tica simulation, cv1\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",cmap=\"fessa\",c=\"cv2\",ax=axs[0])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",c=\"cv2\",cmap=\"fessa\",ax=axs[1])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",c=\"cv2\",cmap=\"fessa\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"biased tica simulation, cv2\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonality  \n",
    "We said that the **ICs** must satisfy two conditions. The first one is that they are uncorrelated, which means that $\\int d \\vec x \\psi_1(\\vec x) \\psi_2(\\vec x) e^{-\\beta U(\\vec x)} = 0$.  \n",
    "But their scalar product on the data will lead to a slightly different result, in this case approximately $0$, but not perfectly $0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boltzmann_product(model,model,X,j=0,k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "tica = TICA_CV(n_features=X.shape[1])\n",
    "tica.to(device)\n",
    "#tica.tica.symmetrize = False\n",
    "t = data['time'].values[::1]\n",
    "X = data[descriptors_names].values[::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "#tica.tica.reg_cholesky=0.000000035\n",
    "tica.fit(X, t, lag=1)\n",
    "\n",
    "tica.to(\"cpu\")\n",
    "feature_names = data[descriptors_names].columns.values\n",
    "tica.set_params({\"feature_names\": feature_names})\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "#print(\"eigenvalues: \",tica.tica.evals_.detach().cpu().numpy())\n",
    "\n",
    "#print(tica.plumed_input().splitlines()[:2])\n",
    "#print(tica.plumed_input().splitlines()[0][8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cv1_tica\"] = np.transpose(tica(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2_tica\"] = np.transpose(tica(torch.Tensor(X)).detach().cpu().numpy())[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "data.plot.hist(y=\"cv1_tica\",bins=20,ax=axs[0],density=True,color=\"b\")\n",
    "data.plot.hist(y=\"cv2_tica\",bins=20,ax=axs[1],density=True,color=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",cmap=\"fessa\",C=\"cv1_tica\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"biased tica simulation, cv1_tica\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",cmap=\"fessa\",C=\"cv1_tica\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",cmap=\"fessa\",C=\"cv1_tica\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,6))\n",
    "    \n",
    "#rmsd_ca end hbonds\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"end\",cmap=\"fessa\",C=\"cv2_tica\",ax=axs[0])\n",
    "axs[0].grid()\n",
    "axs[0].set_title(\"biased tica simulation, cv2_tica\")\n",
    "axs[0].set_ylabel(\"rmsd_ca\")\n",
    "axs[0].set_xlabel(\"end\")\n",
    "\n",
    "data.plot.hexbin(y=\"rmsd_ca\",x=\"hbonds\",cmap=\"fessa\",C=\"cv2_tica\",ax=axs[1])\n",
    "axs[1].grid()\n",
    "axs[1].set_ylabel(\"rmsd_ca\")\n",
    "axs[1].set_xlabel(\"hbonds\")\n",
    "\n",
    "data.plot.hexbin(y=\"hbonds\",x=\"end\",cmap=\"fessa\",C=\"cv2_tica\",ax=axs[2])\n",
    "axs[2].grid()\n",
    "axs[2].set_ylabel(\"hbonds\")\n",
    "axs[2].set_xlabel(\"end\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",c=\"cv1_tica\",cmap=\"fessa\",ax=axs[0])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",c=\"cv1_tica\",cmap=\"fessa\",ax=axs[1])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",cmap=\"fessa\",c=\"cv1_tica\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"biased tica simulation, cv1_tica\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(18,4))\n",
    "data.plot.scatter(x=\"time\",y=\"rmsd_ca\",cmap=\"fessa\",c=\"cv2_tica\",ax=axs[0])\n",
    "data.plot.scatter(x=\"time\",y=\"end\",cmap=\"fessa\",c=\"cv2_tica\",ax=axs[1])\n",
    "data.plot.scatter(x=\"time\",y=\"hbonds\",cmap=\"fessa\",c=\"cv2_tica\",ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"biased tica simulation, cv2_tica\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = data[[\"cv1_tica\",\"cv2_tica\"]].to_numpy()\n",
    "logweight=data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        temp = sim_parameters[\"temp\"], \n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\",\"F(cv2) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(tica cv1,tica cv2)$\")\n",
    "ax.set_ylabel(\"FES [KbT]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
