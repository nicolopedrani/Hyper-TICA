{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- python script for write correct input files for \"ves_md_linearexpansion\" plumed module --#\n",
    "from input_VES import *\n",
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'nstep':200000, #1ns of simulation\n",
    "    'plumedseed':4525,\n",
    "    'friction':10,\n",
    "    'temp':1, #kbt units\n",
    "    #-- upper basin --#\n",
    "    #'initial_position':[0.6,0.02],\n",
    "    #-- middle basin --#\n",
    "    #'initial_position':[-0.05,0.47],\n",
    "    #-- lower basin --#\n",
    "    'initial_position':[1.27],\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :16,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M&uuml;ller Potential \n",
    "Just have a look at the Muller potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- 1d --#\n",
    "\n",
    "x = np.linspace(-1.5,1.5,150)\n",
    "y =  potential1d_function(x)\n",
    "y-=np.min(y)\n",
    "fig,ax = plt.subplots(figsize=(8,8)) \n",
    "\n",
    "ax.plot(x,y)\n",
    "ax.set_xlabel(r\"$p.x$ [L]\")\n",
    "ax.set_ylabel(r\"$U(x)$ [$K_b T$]\")\n",
    "\n",
    "#-- highlight the starting point --#\n",
    "ax.text(1,1,r'$Starting$ $Position$',color=\"red\")\n",
    "draw_circle = plt.Circle((1.27,0), 0.05, color=\"red\")\n",
    "ax.add_artist(draw_circle)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"test_static/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(folder+\"plumed.dat\",\"w\") as file:\n",
    "    print(\"\"\"\n",
    "# vim:ft=plumed\n",
    "\n",
    "# using natural units for Toy Model \n",
    "UNITS NATURAL\n",
    "\n",
    "# compute position for the one particle  \n",
    "p: POSITION ATOM=1\n",
    "# adding external potential \n",
    "potential: CUSTOM ARG=p.x FUNC=\"\"\"+potential1d()+\"\"\" PERIODIC=NO\n",
    "ene: BIASVALUE ARG=potential\n",
    "\n",
    "# definition of Deep-TICA cvs \n",
    "deep: PYTORCH_MODEL FILE=../unbias/deeptica/model.ptc ARG=p.x\n",
    "\n",
    "ext: EXTERNAL ARG=deep.node-0 FILE=STATIC.out\n",
    "# Bias \n",
    "#opes: OPES_METAD ARG=deep.node-0 TEMP=1 PACE=500 FILE=KERNELS BARRIER=8 STATE_WFILE=RestartKernels STATE_WSTRIDE=500*10\n",
    "\n",
    "# Print \n",
    "# STRIDE=100 so that the printed time is in 0.5 ps\n",
    "PRINT FMT=%g STRIDE=100 FILE=COLVAR ARG=deep.node-0,p.x,ene.bias,ext.*\n",
    "\n",
    "ENDPLUMED\n",
    "\"\"\",file=file)\n",
    "\n",
    "#-- write input files for ves module --#\n",
    "generate_input_file(name_file=folder+\"input\",nstep=sim_parameters[\"nstep\"],temp=sim_parameters[\"temp\"],\n",
    "                    friction=sim_parameters[\"friction\"],random_seed=sim_parameters[\"plumedseed\"],\n",
    "                    initial_position=sim_parameters[\"initial_position\"],dim=1)\n",
    "write_coeff(\"0\",folder+\"input\")\n",
    "\n",
    "#-- move necessary files for ves module --#\n",
    "execute(\"mv pot_coeffs_input.data \"+folder,folder=\".\")\n",
    "#execute(\"cp unbias/bias1/STATIC.out \"+ folder, folder=\".\")\n",
    "#-- run plumed --#\n",
    "execute(\"plumed ves_md_linearexpansion input\",folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "x = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.x\").values\n",
    "ax.hist(x,bins=100,color=\"blue\",alpha=0.5,label=\"Trajectory\",density=True)\n",
    "\n",
    "xx = np.linspace(-1.5,1.5,150)\n",
    "y =  potential1d_function(xx)\n",
    "y-=np.min(y)\n",
    "\n",
    "ax.plot(xx,y)\n",
    "ax.set_xlabel(r\"$p.x$ [L]\")\n",
    "ax.set_ylabel(r\"$U(x)$ [$K_b T$]\")\n",
    "\n",
    "ax.legend([r\"U(x)\",\"histogram\"])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "data = load_dataframe(folder+\"COLVAR\") \n",
    "print(data.head())\n",
    "s = data[\"p.x\"].to_numpy()\n",
    "logweight = data[\"ext.bias\"]/sim_parameters[\"temp\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "fes,grid,bounds,error = compute_fes(s, #weights=np.exp(logweight),\n",
    "                                    kbt=sim_parameters[\"temp\"],\n",
    "                                    blocks=sim_parameters[\"blocks\"],\n",
    "                                    bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                    plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(x) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(x)$ [L]\")\n",
    "ax.set_ylabel(r\"FES [$K_b T$]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ext.bias\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "desc = descriptors_names[0]\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,4),sharey=True)\n",
    "\n",
    "data[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2,density=True)\n",
    "data[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\",density=True)\n",
    "ax.set_xlabel(desc + \" [L]\")\n",
    "ax.set_title(desc)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,4),sharey=True)\n",
    "\n",
    "data.plot.scatter(x=\"time\",y=\"p.x\",alpha=1,ax=ax,legend=False,grid=True)\n",
    "ax.set_xlabel(desc + \" [L]\")\n",
    "ax.set_title(desc)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "size = len(data)\n",
    "min_lag,max_lag = 0.5,1 \n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "shuffle = False # if shuffle the data between batches\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "\n",
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 2\n",
    "n_input = len(descriptors_names)\n",
    "train_parameters = {\n",
    "              'descriptors': '^p', # can change during simulation\n",
    "              'nodes':[n_input,10,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-4,\n",
    "              'l2_reg':0,\n",
    "              'num_epochs':1000,\n",
    "              'batchsize': -1, #---> Ã¨ da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "#--------------------------------------#\n",
    "\n",
    "print(train_parameters[\"nodes\"])\n",
    "\n",
    "# how many data in single batch, batchsize\n",
    "n_train = int( size*train_parameters[\"trainsize\"] )\n",
    "n_valid = int( size*(1-train_parameters[\"trainsize\"])-int(10*max_lag) )\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "print(X.shape)\n",
    "\n",
    "logweight = data[\"ext.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight /= sim_parameters[\"temp\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=lag,interval=[0,n_train+n_valid])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.0,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- export checkpoint (for loading the model back to python) and torchscript traced module --#\n",
    "save_folder = folder+\"deeptica/\"\n",
    "try:\n",
    "    os.mkdir(save_folder)\n",
    "except:\n",
    "    print(\"already exists\")\n",
    "#-- move to cpu before saving results --#\n",
    "model.to(\"cpu\")\n",
    "model.export(save_folder)\n",
    "print(\"model saved\")\n",
    "\n",
    "#-- print some useful results --#\n",
    "print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding to data the cvs values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]\n",
    "#data[\"cv3\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,3,figsize=(12,4),sharey=True)\n",
    "data.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"b\")\n",
    "data.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"r\")\n",
    "#data.plot.hist(y=\"cv3\",bins=20,ax=axs[2],density=True,color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the correlation (*Pearson* correlation ,which simply means normed correlation) of the Deep-TICA cvs with the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig,axs = plt.subplots(1,3,figsize=(16,4))\n",
    "#for k,cv in enumerate([\"cv1\",\"cv2\",\"cv3\"]):\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4))\n",
    "for k,cv in enumerate([\"cv1\",\"cv2\"]):\n",
    "    cols = [cv]\n",
    "    cols.extend(data.filter(regex='^p.').columns)\n",
    "    corr = data[cols].corr(method='pearson')\n",
    "\n",
    "    corr[cv].drop(cv).plot(kind='bar', ax=axs[k], rot=35)\n",
    "    axs[k].set_title('Correlation with DeepTICA '+str(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FES estimate from cvs  \n",
    "Obviously from this first simulation it is not possible to found a cvs that from data are able to distinguish all the possible basins. I recall that our approach is a **data drive approach**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = data.filter(regex=\"^cv\").to_numpy()\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight /= sim_parameters[\"temp\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        kbt=sim_parameters[\"temp\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\",\"F(cv2) estimate\",\"F(cv3) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(cv1,cv2,cv3)$\")\n",
    "ax.set_ylabel(\"FES [KbT]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x=\"time\",y=\"p.x\",c=\"cv1\",alpha=1,legend=False,grid=True,cmap=\"fessa\")\n",
    "data.plot.scatter(x=\"time\",y=\"p.x\",c=\"cv2\",alpha=1,legend=False,grid=True,cmap=\"fessa\")\n",
    "#data.plot.scatter(x=\"time\",y=\"p.x\",c=\"cv3\",alpha=1,legend=False,grid=True,cmap=\"fessa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolines  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "xx = np.linspace(-1.5,1.5,150).reshape(150,1)\n",
    "# potential energy\n",
    "y =  potential1d_function(xx)\n",
    "y-=np.min(y)\n",
    "ax.plot(xx,y,linestyle=\"--\",color=\"black\",linewidth=2)\n",
    "# first cv\n",
    "y = np.transpose(model(torch.Tensor(xx)).detach().cpu().numpy())[0]*10#+1\n",
    "ax.plot(xx,y,color=\"red\",label=\"Deep-TICA 1\")\n",
    "# second cv\n",
    "y = np.transpose(model(torch.Tensor(xx)).detach().cpu().numpy())[1]*10#+1\n",
    "ax.plot(xx,y,color=\"blue\",label=\"Deep-TICA 2\")\n",
    "# third cv\n",
    "#y = np.transpose(model(torch.Tensor(xx)).detach().cpu().numpy())[2]*10#+1\n",
    "#ax.plot(xx,y,color=\"green\",label=\"Deep-TICA 3\")\n",
    "\n",
    "ax.set_xlabel(\"p.x\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "tica = TICA_CV(n_features=X.shape[1])\n",
    "tica.to(device)\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "tica.fit(X, t, lag=min_lag)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "tica.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",tica.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cv1_tica\"] = np.transpose(tica(torch.Tensor(X)).detach().cpu().numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(4,4),sharey=True)\n",
    "data.plot.hist(y=\"cv1_tica\",bins=20,ax=axs,density=True,color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the correlation (*Pearson* correlation ,which simply means normed correlation) of the Deep-TICA cvs with the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,1,figsize=(4,4))\n",
    "for k,cv in enumerate([\"cv1_tica\"]):\n",
    "    cols = [cv]\n",
    "    cols.extend(data.filter(regex='^p.').columns)\n",
    "    corr = data[cols].corr(method='pearson')\n",
    "\n",
    "    corr[cv].drop(cv).plot(kind='bar', ax=axs, rot=35)\n",
    "    axs.set_title('Correlation with DeepTICA '+str(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FES estimate from cvs  \n",
    "Obviously from this first simulation it is not possible to found a cvs that from data are able to distinguish all the possible basins. I recall that our approach is a **data drive approach**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = data[\"cv1_tica\"].to_numpy()\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight /= sim_parameters[\"temp\"]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(1):\n",
    "    fes,grid,bounds,error = compute_fes(s, weights=np.exp(logweight),\n",
    "                                        kbt=sim_parameters[\"temp\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(cv1_tica)$\")\n",
    "ax.set_ylabel(\"FES [KbT]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x=\"time\",y=\"p.x\",c=\"cv1_tica\",alpha=1,legend=False,grid=True,cmap=\"fessa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "xx = np.linspace(-1.5,1.5,150).reshape(150,1)\n",
    "# potential energy\n",
    "y =  potential1d_function(xx)\n",
    "y-=np.min(y)\n",
    "ax.plot(xx,y)\n",
    "# first cv\n",
    "y = np.transpose(tica(torch.Tensor(xx)).detach().cpu().numpy())[0]\n",
    "y -= np.min(y)\n",
    "ax.plot(xx,y,color=\"red\",label=\"TICA 1\")\n",
    "\n",
    "ax.set_xlabel(\"p.x\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('mlcvs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "34f06b9f9681e9a7231f3100f6e351611d3f9f188d680707206d70c247429f78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
