{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- necessary modules --#\n",
    "import numpy as np\n",
    "np.random.seed(13)\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "import matplotlib as mpl\n",
    "from scipy import integrate\n",
    "\n",
    "#-- to computer fes --#\n",
    "from mlcvs.utils.fes import compute_fes\n",
    "\n",
    "#-- to run process from jupyter --#\n",
    "import subprocess\n",
    "import os\n",
    "from pathlib import Path\n",
    "# execute bash command in the given folder\n",
    "def execute(command, folder, background=False):\n",
    "    cmd = subprocess.run(command, cwd=folder, shell=True, capture_output = True, text=True, close_fds=background)\n",
    "    if cmd.returncode == 0:\n",
    "        print(f'Completed: {command}')\n",
    "    else:\n",
    "        print(cmd.stderr)\n",
    "\n",
    "#-- python script for write correct input files for \"ves_md_linearexpansion\" plumed module --#\n",
    "from input_VES import *\n",
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'nstep':100000, \n",
    "    'plumedseed':4525,\n",
    "    'friction':10,\n",
    "    'temp':1, #kbt units\n",
    "    #-- upper basin --#\n",
    "    #'initial_position':[0.6,0.02],\n",
    "    #-- middle basin --#\n",
    "    #'initial_position':[-0.05,0.47],\n",
    "    #-- lower basin --#\n",
    "    'initial_position':[-0.55,1.45],\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :16,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"test_corr/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(folder+\"plumed.dat\",\"w\") as file:\n",
    "    print(\"\"\"\n",
    "# vim:ft=plumed\n",
    "\n",
    "# using natural units for Toy Model \n",
    "UNITS NATURAL\n",
    "\n",
    "# compute position for the one particle  \n",
    "p: POSITION ATOM=1\n",
    "# adding external potential \n",
    "potential: CUSTOM ARG=p.x,p.y FUNC=\"\"\"+Mullerpot(),\"\"\"PERIODIC=NO\n",
    "ene: BIASVALUE ARG=potential\n",
    "\n",
    "# Bias \n",
    "opes: OPES_METAD ARG=p.x TEMP=1 PACE=500 FILE=KERNELS BARRIER=6 STATE_WFILE=RestartKernels STATE_WSTRIDE=500*10\n",
    "\n",
    "# Print \n",
    "# STRIDE=200 so that the printed time is in 1 ps\n",
    "PRINT FMT=%g STRIDE=200 FILE=COLVAR ARG=p.x,p.y,ene.bias,opes.*\n",
    "\n",
    "ENDPLUMED\n",
    "\"\"\",file=file)\n",
    "\n",
    "#-- write input files for ves module --#\n",
    "generate_input_file(name_file=folder+\"input\",nstep=sim_parameters[\"nstep\"],temp=sim_parameters[\"temp\"],\n",
    "                    friction=sim_parameters[\"friction\"],random_seed=sim_parameters[\"plumedseed\"],\n",
    "                    initial_position=sim_parameters[\"initial_position\"])\n",
    "write_coeff(\"0\",folder+\"input\")\n",
    "\n",
    "#-- move necessary files for ves module --#\n",
    "execute(\"mv pot_coeffs_input.data \"+folder,folder=\".\")\n",
    "#-- run plumed --#\n",
    "execute(\"plumed ves_md_linearexpansion input\",folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "x,y = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.x\").values,load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.y\").values\n",
    "ax.scatter(x,y,color=\"black\",alpha=1,label=\"Trajectory\",s=10)\n",
    "\n",
    "#-- prepare grid points\n",
    "y = np.linspace(-0.3,2.1,150)\n",
    "x = np.linspace(-1.8,1.2,150)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = Mullerfunction(X,Y)\n",
    "#-- set to 0 the lowest basin --#\n",
    "Z-=np.min(Z)\n",
    "\n",
    "#bounds = np.arange(np.min(Z), np.max(Z), 5.)\n",
    "bounds = np.arange(0, 16, 1.)\n",
    "cmap = plt.cm.get_cmap('fessa',len(bounds))\n",
    "colors = list(cmap(np.arange(len(bounds))))\n",
    "cmap = mpl.colors.ListedColormap(colors[:-1], \"\")\n",
    "# set over-color to last color of list \n",
    "cmap.set_over(\"white\")\n",
    "\n",
    "c = plt.pcolormesh(X, Y, Z, cmap=cmap,shading='auto',alpha=1,zorder=-1,\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False)\n",
    ")\n",
    "c = plt.contourf(X, Y, Z, bounds , cmap=cmap,shading='auto',alpha=1,zorder=-1, linewidth=10,\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"Energy Surface\"\n",
    ")\n",
    "fig.colorbar(c, ax=ax)\n",
    "c = plt.contour(X, Y, Z, bounds , cmap=\"jet\",shading='auto',alpha=1, linewidth=5, linestyles=\"dashed\")\n",
    "#-- if put label on isolines --#\n",
    "#c.clabel()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$p.x$\")\n",
    "ax.set_ylabel(r\"$p.y$\")\n",
    "ax.set_title(r'$U(x,y)$')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#-- estimation of Free Energy Surface 1D --#\n",
    "s = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p\").to_numpy()\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0]/sim_parameters[\"temp\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        kbt=sim_parameters[\"temp\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(x) estimate\",\"F(y) estimate\"])   \n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$(x,y)$\")\n",
    "ax.set_ylabel(\"FES [KbT]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2,density=True)\n",
    "    data[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\",density=True)\n",
    "    ax.set_title(desc)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[::1].plot.scatter(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,linewidth=2,marker=\"^\")\n",
    "    data[::1].plot.line(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,color=\"grey\")\n",
    "    ax.set_title(desc)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lag,max_lag = 100,300 \n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "shuffle = False # if shuffle the data between batches\n",
    "\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "print(data)\n",
    "descriptors_names = data.filter(regex='^p.').columns.values\n",
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 2 # 2 non linear combination of the descriptors  \n",
    "n_input = len(descriptors_names) # can change..\n",
    "train_parameters = {\n",
    "              'descriptors': '^p.', # can change during simulation\n",
    "              'nodes':[n_input,10,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':200,\n",
    "              'batchsize': -1, #---> Ã¨ da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data in single batch, batchsize\n",
    "n_train = int( len(data)*train_parameters[\"trainsize\"] )\n",
    "n_valid = int(len(data)*(1-train_parameters[\"trainsize\"]))-2*int(min_lag)\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values \n",
    "\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight /= sim_parameters[\"temp\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "#tprime = t\n",
    "#logweight = None\n",
    "\n",
    "'''\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=np.round(lag,3),logweights=logweight,tprime=tprime,interval=[0,n_train+n_valid])\n",
    "    print(len(dataset))\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,x_lag,w_t,w_lag =find_time_lagged_configurations(X, t=tprime,lag=min_lag)\n",
    "x_t = torch.Tensor(x_t)\n",
    "x_lag = torch.Tensor(x_lag)\n",
    "w_t = torch.Tensor(w_t)\n",
    "w_lag = torch.Tensor(w_lag)\n",
    "print(\"shape of x_t:\\t\", x_t.shape)\n",
    "print(\"shape of x_lag:\\t\", x_lag.shape)\n",
    "\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "\n",
    "# compute mean-free variables\n",
    "#I try change this one\n",
    "ave = model.tica.compute_average(x_t,w_t)\n",
    "print(ave)\n",
    "x = torch.Tensor(data[[\"p.x\",\"p.y\"]].to_numpy())\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy()); logweight /= sim_parameters[\"temp\"]\n",
    "ave = model.tica.compute_average(x,torch.Tensor(np.exp(logweight)))\n",
    "#ave = model.tica.compute_average(x,w=None)\n",
    "print(ave)\n",
    "x_t.sub_(ave)\n",
    "x_lag.sub_(ave)\n",
    "\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute correlation matrix C0\n",
    "corr_x = torch.einsum('ij, ik, i -> jk', x_t, x_t, w_t )\n",
    "corr_x /= torch.sum(w_t)\n",
    "corr_xlag = torch.einsum('ij, ik, i -> jk', x_lag, x_lag, w_lag )\n",
    "corr_xlag /= torch.sum(w_lag)\n",
    "# enforce symmetrization\n",
    "C0 = 0.5*(corr_x + corr_xlag.T)\n",
    "\n",
    "#compute correlation matrix Clag\n",
    "corr_x_xlag = torch.einsum('ij, ik, i -> jk', x_t, x_lag, w_lag )\n",
    "corr_x_xlag /= torch.sum(w_lag)\n",
    "corr_xlag_x = torch.einsum('ij, ik, i -> jk', x_lag, x_t, w_lag )\n",
    "corr_xlag_x /= torch.sum(w_lag)\n",
    "# enforce symmetrization\n",
    "Clag = 0.5*(corr_x_xlag + corr_xlag_x.T)\n",
    "\n",
    "print(\"C0 \\t:\",C0)\n",
    "print(\"Clag \\t:\",Clag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t,x_lag,w_t,w_lag =find_time_lagged_configurations(X, t=tprime,lag=min_lag)\n",
    "x_t = torch.Tensor(x_t)\n",
    "x_lag = torch.Tensor(x_lag)\n",
    "w_t = torch.Tensor(w_t)\n",
    "w_lag = torch.Tensor(w_lag)\n",
    "\n",
    "ave = model.tica.compute_average(x_t,w_t)\n",
    "x_t.sub_(ave)\n",
    "x_lag.sub_(ave)\n",
    "\n",
    "print(\"Previous method\")\n",
    "C0,Clag = model.tica.correlation_matrices(x=x_t,x_lag=x_lag,w=w_t,w_lag=w_lag)\n",
    "print(\"C0 \\t:\",C0)\n",
    "print(\"Clag \\t:\",Clag)\n",
    "\n",
    "print(\"Luigi method\")\n",
    "C_0 = model.tica.compute_correlation_matrix(x_t,x_t,w_t)\n",
    "C_lag = model.tica.compute_correlation_matrix(x_t,x_lag,w_lag)\n",
    "print(\"C0 \\t:\",C0)\n",
    "print(\"Clag \\t:\",Clag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.001,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
