{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- python script for write correct input files for \"ves_md_linearexpansion\" plumed module --#\n",
    "from input_VES import *\n",
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'nstep':50000000, \n",
    "    'plumedseed':4525,\n",
    "    'friction':10,\n",
    "    'temp':0.5, #kbt units\n",
    "    'initial_position':[-1,0],\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :16,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"benchmark/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(folder+\"plumed.dat\",\"w\") as file:\n",
    "    print(\"\"\"\n",
    "# vim:ft=plumed\n",
    "\n",
    "# using natural units for Toy Model \n",
    "UNITS NATURAL\n",
    "\n",
    "# compute position for the one particle  \n",
    "p: POSITION ATOM=1\n",
    "# adding external potential \n",
    "potential: CUSTOM ARG=p.x,p.y FUNC=\"\"\"+Mullerpot(),\"\"\"PERIODIC=NO\n",
    "ene: BIASVALUE ARG=potential\n",
    "\n",
    "# Bias \n",
    "opes: OPES_METAD ARG=p.x,p.y TEMP=\"\"\"+str(sim_parameters[\"temp\"])+\"\"\" PACE=500 FILE=KERNELS BIASFACTOR=1.2 BARRIER=3 STATE_WFILE=RestartKernels STATE_WSTRIDE=500*10\n",
    "\n",
    "# Print \n",
    "# STRIDE=200 so that the printed time is in 1 ps\n",
    "PRINT FMT=%g STRIDE=200 FILE=COLVAR ARG=p.x,p.y,ene.bias,opes.*\n",
    "\n",
    "ENDPLUMED\n",
    "\"\"\",file=file)\n",
    "\n",
    "#-- write input files for ves module --#\n",
    "generate_input_file(name_file=folder+\"input\",nstep=sim_parameters[\"nstep\"],temp=sim_parameters[\"temp\"],\n",
    "                    friction=sim_parameters[\"friction\"],random_seed=sim_parameters[\"plumedseed\"],\n",
    "                    initial_position=sim_parameters[\"initial_position\"])\n",
    "write_coeff(\"0\",folder+\"input\")\n",
    "\n",
    "#-- move necessary files for ves module --#\n",
    "execute(\"mv pot_coeffs_input.data \"+folder,folder=\".\")\n",
    "#-- run plumed --#\n",
    "execute(\"plumed ves_md_linearexpansion input\",folder=folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "x,y = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.x\").values,load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.y\").values\n",
    "ax.scatter(x,y,color=\"black\",alpha=1,label=\"Trajectory\",s=10)\n",
    "\n",
    "#-- prepare grid points\n",
    "y = np.linspace(-2,2,300)\n",
    "x = np.linspace(-2,2,300)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = potential2D(X,Y)\n",
    "#-- set to 0 the lowest basin --#\n",
    "Z-=np.min(Z)\n",
    "\n",
    "#bounds = np.arange(np.min(Z), np.max(Z), 5.)\n",
    "bounds = np.arange(0, 30, 0.5)\n",
    "cmap = plt.cm.get_cmap('fessa',len(bounds))\n",
    "colors = list(cmap(np.arange(len(bounds))))\n",
    "cmap = mpl.colors.ListedColormap(colors[:-1], \"\")\n",
    "# set over-color to last color of list \n",
    "cmap.set_over(\"white\")\n",
    "\n",
    "c = plt.pcolormesh(X, Y, Z, cmap=cmap,shading='auto',alpha=1,zorder=-1,\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False)\n",
    ")\n",
    "c = plt.contourf(X, Y, Z, bounds , cmap=cmap,shading='auto',alpha=1,zorder=-1, linewidth=10,\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"Energu Surface\"\n",
    ")\n",
    "fig.colorbar(c, ax=ax)\n",
    "c = plt.contour(X, Y, Z, bounds , cmap=\"jet\",shading='auto',alpha=1, linewidth=5, linestyles=\"dashed\")\n",
    "#-- if put label on isolines --#\n",
    "#c.clabel()\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$p.x$ [L]\")\n",
    "ax.set_ylabel(r\"$p.y$ [L]\")\n",
    "ax.set_title(r'$U(x,y)$ [$K_b T$]')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface 1D --#\n",
    "s = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p\").to_numpy()\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0]/sim_parameters[\"temp\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        kbt=sim_parameters[\"temp\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(x) estimate\",\"F(y) estimate\"])   \n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$(x,y)$\")\n",
    "ax.set_ylabel(\"FES [KbT]\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2,density=True)\n",
    "    data[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\",density=True)\n",
    "    ax.set_title(desc)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[::100].plot.scatter(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,linewidth=2,marker=\"^\")\n",
    "    data[::100].plot.line(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,color=\"grey\")\n",
    "    ax.set_title(desc)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lag,max_lag = 1,5 \n",
    "n = 5 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "shuffle = False # if shuffle the data between batches\n",
    "\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "data = load_dataframe(folder+\"COLVAR\")[:1000]\n",
    "print(data)\n",
    "descriptors_names = data.filter(regex='^p.').columns.values\n",
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 2 # 2 non linear combination of the descriptors  \n",
    "n_input = len(descriptors_names) # can change..\n",
    "train_parameters = {\n",
    "              'descriptors': '^p.', # can change during simulation\n",
    "              'nodes':[n_input,10,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':200,\n",
    "              'batchsize': -1, #---> Ã¨ da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many data in single batch, batchsize\n",
    "n_train = int( len(data)*train_parameters[\"trainsize\"] )\n",
    "n_valid = int(len(data)*(1-train_parameters[\"trainsize\"]))-2*int(min_lag)\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values \n",
    "\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight /= sim_parameters[\"temp\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "tprime = None\n",
    "logweight = None\n",
    "\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=lag,interval=[0,n_train+n_valid])\n",
    "    print(len(dataset))\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.001,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Free Energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- each step is 1ps --#\n",
    "data = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.x\").to_numpy()[:]\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0][:]\n",
    "logweight= (logweight-np.max(logweight))/sim_parameters[\"temp\"]\n",
    "\n",
    "s = data[:]\n",
    "weight = np.exp(logweight[:])\n",
    "fes,grid,bounds,error = compute_fes(s, weights=weight,\n",
    "                                    kbt=sim_parameters[\"temp\"],\n",
    "                                    blocks=2,\n",
    "                                    bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                    plot=False)\n",
    "ind1 = (grid<0) & (grid>-1.3)\n",
    "ind2 = (grid>0) & (grid<1)\n",
    "grid1 = grid[ ind1 ]\n",
    "grid2 = grid[ ind2 ] \n",
    "I1 = integrate.trapz(np.exp(-fes[ind1]/sim_parameters[\"temp\"]), grid1)\n",
    "I2 = integrate.trapz(np.exp(-fes[ind2]/sim_parameters[\"temp\"]), grid2)\n",
    "\n",
    "res =(sim_parameters[\"temp\"])*np.log(I1/I2)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- each step is 1ps --#\n",
    "#-- we are interested in the first 50 ns --#\n",
    "last = 1*1000*50 #last ns\n",
    "data = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p.x\").to_numpy()[:last]\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0][:last]\n",
    "logweight= (logweight-np.max(logweight))/sim_parameters[\"temp\"]\n",
    "#-- each step is 1ps --#\n",
    "#-- with CLEAR set to 1000 I perform the estimation every ns --#\n",
    "CLEAR=500\n",
    "\n",
    "deltaf = np.empty(0)\n",
    "for el in np.arange(CLEAR,len(data)+CLEAR,CLEAR):\n",
    "    s = data[:el]\n",
    "    weight = np.exp(logweight[:el])\n",
    "    fes,grid,bounds,error = compute_fes(s, weights=weight,\n",
    "                                        kbt=sim_parameters[\"temp\"],\n",
    "                                        blocks=2,\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=False)\n",
    "    ind1 = (grid<0) & (grid>-1.3)\n",
    "    ind2 = (grid>0) & (grid<1)\n",
    "    grid1 = grid[ ind1 ]\n",
    "    grid2 = grid[ ind2 ] \n",
    "    I1 = integrate.trapz(np.exp(-fes[ind1]/sim_parameters[\"temp\"]), grid1)\n",
    "    I2 = integrate.trapz(np.exp(-fes[ind2]/sim_parameters[\"temp\"]), grid2)\n",
    "    \n",
    "    deltaf = np.append(deltaf,(sim_parameters[\"temp\"])*np.log(I1/I2))\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot(np.arange(len(deltaf)),deltaf,label=\"Estimate\")\n",
    "res = np.full(len(deltaf),res)\n",
    "err = np.full(len(deltaf),0.5*sim_parameters[\"temp\"])\n",
    "ax.plot(np.arange(len(deltaf)),res,linestyle='--',linewidth=3,color=\"g\",label=\"ref\")\n",
    "ax.fill_between(np.arange(len(deltaf)) , res-err, res+err , color=\"r\",zorder=0,alpha=0.3)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$t$ [ps$\\times$\"+str(CLEAR)+\"]\")\n",
    "ax.set_ylabel(r\"$\\Delta F$ [kbT]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
