{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb=0.008314\n",
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'temp':300, \n",
    "    'beta': 1./(300*kb),\n",
    "    'kbt': None,\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :70,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"unbias_A/bias1/\"\n",
    "#execute(\"./run_gromacs.sh\",folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "olddata = load_dataframe(\"unbias_A/COLVAR\")\n",
    "descriptors_names = data.filter(regex='^d[^a-z]').columns.values\n",
    "data_complete = load_dataframe(\"../../angles/COLVAR\")\n",
    "X_complete = data_complete[descriptors_names].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the unbias data to the bias one\n",
    "In order to use also the old data to obtain an estime on the fly of TICA cv we need to concat both data together  \n",
    "The time of the bias data must be increase by the last valued of the old_data last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"time\"] = data[\"time\"] + olddata[\"time\"].tail(1).values\n",
    "data[\"opes.bias\"] = data[\"opes.bias\"]-min(data[\"opes.bias\"])\n",
    "newdata = pd.concat([ olddata,data],ignore_index=True).replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = load_dataframe(folder+\"COLVAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
    "#load_dataframe(folder+\"COLVAR\").plot.scatter(y=\"psi\",x=\"phi\",ax=ax)\n",
    "newdata.plot.scatter(y=\"psi\",x=\"phi\",ax=ax)\n",
    "\n",
    "fes = np.loadtxt(\"../../angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"../../angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"../../angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax.contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$\\phi$\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_dataframe(folder+\"COLVAR\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
    "newdata.plot.scatter(x=\"time\",y=\"psi\",ax=ax, color=\"b\", label=\"psi\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"phi\",ax=ax, color=\"r\", label=\"phi\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"omega\",ax=ax, color=\"y\", label=\"omega\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"theta\",ax=ax, color=\"g\", label=\"theta\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,4,figsize=(16,6))\n",
    "newdata.plot.scatter(x=\"time\",y=\"psi\",ax=axs[0], color=\"b\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"phi\",ax=axs[1], color=\"r\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"omega\",ax=axs[2], color=\"y\")\n",
    "newdata.plot.scatter(x=\"time\",y=\"theta\",ax=axs[3], color=\"g\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "#load_dataframe(folder+\"COLVAR\").plot.scatter(y=\"omega\",x=\"psi\",ax=ax)\n",
    "newdata.plot.scatter(y=\"omega\",x=\"psi\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    newdata[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2,density=True)\n",
    "    newdata[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\",density=True)\n",
    "    ax.set_title(desc)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4))\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    newdata[::10].plot.scatter(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,linewidth=2,marker=\"^\")\n",
    "    newdata[::10].plot.line(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,color=\"grey\")\n",
    "    ax.set_title(desc)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridspec_fes(s,logweight,sim_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_dataframe(folder+\"COLVAR\")\n",
    "descriptors_names = data.filter(regex='^d[^a-z]').columns.values\n",
    "\n",
    "fig,axs = plt.subplots(5,9,figsize=(22,10),sharey=True)\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    newdata[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2)#,density=True)\n",
    "    newdata[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\")#,density=True)\n",
    "    ax.set_title(desc)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TRAINING PARAMETERS --#\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]',\n",
    "              'lag_time':1,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              #if reweight the timescale\n",
    "              \"reweighting\": True,\n",
    "              \"step\": 1 #se prendo tutti i valori fallisce il cholesky decomposition.. issue con pytorch\n",
    "              }\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = np.linspace(0.5,50,50)\n",
    "time = []\n",
    "torch.manual_seed(21)\n",
    "timescale = np.empty(len(lags))\n",
    "for i,lag in enumerate(lags):\n",
    "    train_parameters[\"lag_time\"] = lag\n",
    "    #print(\"lag time \", lag)\n",
    "    model,logweight,X,names = training(newdata,sim_parameters[\"beta\"],train_parameters)\n",
    "\n",
    "    #-- move the model back to cpu for convenience --# \n",
    "    model.to('cpu')\n",
    "\n",
    "    timescale[i] = model.tica.evals_.detach().cpu().numpy()[0]-model.tica.evals_.detach().cpu().numpy()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lags,timescale)\n",
    "print(timescale)\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepTICA Analysis and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "train_parameters[\"lag_time\"] = 1\n",
    "model,logweight,X,names = training(newdata,sim_parameters[\"beta\"],train_parameters,tprime=None)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())\n",
    "print(\"gap: \", model.tica.evals_.detach().cpu().numpy()[0]-model.tica.evals_.detach().cpu().numpy()[1])\n",
    "\n",
    "model.set_params({\"feature_names\": names})\n",
    "print( model.plumed_input().splitlines()[:2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdata.filter(regex=train_parameters[\"descriptors\"]).values\n",
    "newdata[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "newdata[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]\n",
    "newdata[\"cv3\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[2]\n",
    "newdata[\"cv4\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[3]\n",
    "data_complete[\"cv1\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[0]\n",
    "data_complete[\"cv2\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[1]\n",
    "data_complete[\"cv3\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[2]\n",
    "data_complete[\"cv4\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,4,figsize=(18,6),sharey=True)\n",
    "newdata.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"b\",label=\"cv1 data\")\n",
    "newdata.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"b\",label=\"cv2 data\")\n",
    "newdata.plot.hist(y=\"cv3\",bins=20,ax=axs[2],density=True,color=\"b\",label=\"cv3 data\")\n",
    "newdata.plot.hist(y=\"cv4\",bins=20,ax=axs[3],density=True,color=\"b\",label=\"cv4 data\")\n",
    "data_complete.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,histtype='step',color=\"r\",linewidth=2,label=\"cv1 data complete\")\n",
    "data_complete.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,histtype='step',color=\"r\",linewidth=2,label=\"cv2 data complete\")\n",
    "data_complete.plot.hist(y=\"cv3\",bins=20,ax=axs[2],density=True,histtype='step',color=\"r\",linewidth=2,label=\"cv3 data complete\")\n",
    "data_complete.plot.hist(y=\"cv4\",bins=20,ax=axs[3],density=True,histtype='step',color=\"r\",linewidth=2,label=\"cv4 data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the correlation (*Pearson* correlation ,which simply means normed correlation) of the Deep-TICA cvs with the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,1,figsize=(16,24),sharex=True)\n",
    "for k,cv in enumerate([\"cv1\",\"cv2\",\"cv3\",\"cv4\"]):\n",
    "    cols = [cv]\n",
    "    cols.extend(newdata.filter(regex=train_parameters[\"descriptors\"]).columns)\n",
    "    corr = newdata[cols].corr(method='pearson')\n",
    "    corr[cv].drop(cv).plot(kind='bar', ax=axs[k], rot=35, color=\"b\",label=r\"$C(tica|desc)$\")\n",
    "    axs[k].set_title('Correlation with TICA '+str(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "for k,ax in enumerate(axs):\n",
    "    newdata.plot.scatter(y=\"psi\",x=\"phi\",c=\"cv\"+str(k+1),cmap=\"Set1\",ax=ax)\n",
    "    ax.set_xlabel(r\"$\\phi$\")\n",
    "    ax.set_ylabel(r\"$\\psi$\")\n",
    "    ax.set_title('TICA '+str(k+1))\n",
    "plt.tight_layout()\n",
    "fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "for k,ax in enumerate(axs):\n",
    "    data_complete.plot.scatter(y=\"psi\",x=\"phi\",c=\"cv\"+str(k+1),cmap=\"Set1\",ax=ax)\n",
    "    ax.set_xlabel(r\"$\\phi$\")\n",
    "    ax.set_ylabel(r\"$\\psi$\")\n",
    "    ax.set_title('TICA '+str(k+1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"psi\",\"phi\",\"omega\",\"theta\"]\n",
    "fig,axs = plt.subplots(1,4,figsize=(16,4))\n",
    "for i,ax in enumerate(axs):\n",
    "    newdata.plot.scatter(y=names[i],x=\"time\",c=\"cv1\",cmap=\"fessa\",ax=ax)\n",
    "plt.tight_layout()\n",
    "fig,axs = plt.subplots(1,4,figsize=(16,4))\n",
    "for i,ax in enumerate(axs):\n",
    "    newdata.plot.scatter(y=names[i],x=\"time\",c=\"cv2\",cmap=\"fessa\",ax=ax)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(16,4))\n",
    "for i,ax in enumerate(axs):\n",
    "    data_complete.plot.scatter(y=names[i],x=\"time\",c=\"cv1\",cmap=\"fessa\",ax=ax)\n",
    "plt.tight_layout()\n",
    "fig,axs = plt.subplots(1,2,figsize=(16,4))\n",
    "for i,ax in enumerate(axs):\n",
    "    data_complete.plot.scatter(y=names[i],x=\"time\",c=\"cv2\",cmap=\"fessa\",ax=ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FES estimate from new cvs   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = newdata.filter(regex=\"^cv\").to_numpy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "for i in range(4):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        temp=sim_parameters[\"temp\"],\n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "ax.legend([\"F(cv1) estimate\",\"F(cv2) estimate\",\"F(cv3) estimate\",\"F(cv4) estimate\"])   \n",
    "ax.grid()\n",
    "plt.tight_layout()\n",
    "ax.set_xlabel(r\"$(cvs)$\")\n",
    "ax.set_ylabel(\"FES [Kj/mol]\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonality  \n",
    "We said that the **ICs** must satisfy two conditions. The first one is that they are uncorrelated, which means that $\\int d \\vec x \\psi_1(\\vec x) \\psi_2(\\vec x) e^{-\\beta U(\\vec x)} = 0$.  \n",
    "But their scalar product on the data will lead to a slightly different result, in this case approximately $0$, but not perfectly $0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boltzmann_product(model,model,X,j=0,k=1,logweight=logweight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
