{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- useful python script for training the DeepTICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb=0.008314\n",
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'temp':300, \n",
    "    'beta': 1./(300*kb),\n",
    "    'kbt': None,\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :70,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"angles/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(folder+\"plumed.dat\",\"w\") as file:\n",
    "    print(\"\"\"\n",
    "# vim:ft=plumed\n",
    "\n",
    "MOLINFO STRUCTURE=input.ala2.pdb\n",
    "phi: TORSION ATOMS=@phi-2\n",
    "psi: TORSION ATOMS=@psi-2\n",
    "ene: ENERGY\n",
    "\n",
    "INCLUDE FILE=plumed_descriptors.data\n",
    "\n",
    "opes: OPES_METAD ARG=phi,psi TEMP=300 PACE=500 FILE=KERNELS RESTART=NO BARRIER=40 STATE_WFILE=RestartKernels STATE_WSTRIDE=500*10\n",
    "\n",
    "PRINT FMT=%g STRIDE=500 FILE=COLVAR ARG=*\n",
    "\n",
    "ENDPLUMED\n",
    "\"\"\",file=file)\n",
    "\n",
    "#-- run gromacs --#\n",
    "#execute(\"cp script/input.* script/plumed_descriptors.data \"+folder,folder=\".\")\n",
    "#execute(\"./run_gromacs.sh\",folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "load_dataframe(folder+\"COLVAR\").plot.scatter(y=\"psi\",x=\"phi\",c=\"opes.bias\",cmap=\"fessa\",ax=ax)\n",
    "ax.set_xlabel(r\"$\\phi$\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig.savefig(folder+\"images/\"+\"traj.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data.hist(column=\"opes.bias\",ax=ax)\n",
    "ax.set_yscale(\"log\")\n",
    "fig.savefig(folder+\"images/\"+\"bias_hist.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data.hist(column=\"opes.bias\",ax=ax,cumulative=True)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data[\"opes.bias\"].plot.kde(ax=ax)\n",
    "#ax.set_yscale(\"log\")\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "print(33.28968972894314 - max(data[\"opes.bias\"]))\n",
    "delta = 33.28968972894314 - max(data[\"opes.bias\"])\n",
    "#data[\"opes.bias\"] -= (data[\"opes.bias\"].min())\n",
    "data[\"opes.bias\"] += delta \n",
    "#data[\"opes.bias\"] *= -1\n",
    "data.plot.scatter(x=\"phi\",y=\"opes.bias\",ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref from long unbias 1555270 ps\n",
    "\n",
    "# I want to estimate the escape time from basin A to basin B and viceversa\n",
    "# the idea is the following: take the time series and divide the time series in this way \n",
    "# interval for phi : [-pi,0] and [0,pi]\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "data[\"opes.bias\"] += delta#(40-max(data[\"opes.bias\"]))\n",
    "from_time = 0#30000\n",
    "data = data[from_time:]\n",
    "\n",
    "print(len(data))\n",
    "data = data[:]\n",
    "print(len(data))\n",
    "\n",
    "indeces_basinA = ( (data[\"phi\"] < 0) ) #| (data[\"phi\"] > 3) ) #& ( (data[\"psi\"] > -1) | (data[\"psi\"] < -2.5) ) )\n",
    "data[indeces_basinA].plot.scatter(x=\"phi\",y=\"psi\")\n",
    "data[indeces_basinA].hist(column=\"opes.bias\")\n",
    "#print(data[indeces_basinA].index) \n",
    "#indeces_basinB = ( (data[\"phi\"] > 0) & (data[\"phi\"] < np.pi) )\n",
    "\n",
    "time = 0\n",
    "times = []\n",
    "prev_index = -1 \n",
    "dt = 1#data[\"time\"][1]-data[\"time\"][0]\n",
    "\n",
    "for index in (data[indeces_basinA].index-from_time):\n",
    "    #print(index)\n",
    "    if index == prev_index+1:\n",
    "        time += dt * np.exp( sim_parameters[\"beta\"] * data[\"opes.bias\"].to_numpy()[index] )\n",
    "    else:\n",
    "        times.append(time)\n",
    "        time = 0\n",
    "    prev_index = index\n",
    "#print(times)\n",
    "times = pd.DataFrame(times,columns=[\"times\"])\n",
    "times = times[times[\"times\"]>1000000] # problema nel definire la regione in cui calcolare questo elapsed time. E allo stesso tempo\n",
    "                                      # su come riscalare il potenziale\n",
    "print(times[1:].max())\n",
    "print(times[1:].min())\n",
    "print(times[1:].head())\n",
    "\n",
    "print( times[1:].std() , times[1:].mean())\n",
    "\n",
    "ref = 1555270 \n",
    "print(times.mean()-ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data = data[data[\"opes.bias\"]>-5]\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "data.plot.scatter(y=\"psi\",x=\"phi\",c=\"opes.bias\",cmap=\"fessa\",ax=ax)\n",
    "ax.set_xlabel(r\"$\\phi$\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig.savefig(folder+\"images/\"+\"traj.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- estimation of Free Energy Surface --#\n",
    "s = load_dataframe(folder+\"COLVAR\").filter(regex=\"^p\").to_numpy()\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "logweight=( data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy()) )*sim_parameters[\"beta\"]\n",
    "\n",
    "''' questo riscalamento che uso non dà una stima vera delle free energy. Infatti è come se cambiassi la temperatura\n",
    "    e ottengo qualcosa molto simile a non usare i pesi, cioè stime di una simulazione unbias come se non l'avessi nemmeno biasiata\n",
    "logweight=( data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy()) )\n",
    "logweight /= np.abs(np.min(logweight))\n",
    "logweight *= sim_parameters[\"beta\"]\n",
    "'''\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "for i in range(2):\n",
    "    fes,grid,bounds,error = compute_fes(s[:,i], weights=np.exp(logweight),\n",
    "                                        temp=sim_parameters[\"temp\"],\n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=sim_parameters[\"blocks\"],\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=True, plot_max_fes=sim_parameters[\"plot_max_fes\"], ax = ax)\n",
    "    condition = (grid < 0.04) & (grid > 0.03)\n",
    "    print(np.where(condition))\n",
    "    print(fes[50])\n",
    "\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "delta = 33.28968972894314 - max(data[\"opes.bias\"])\n",
    "data[\"opes.bias\"] += delta \n",
    "data.plot.scatter(x=\"phi\",y=\"opes.bias\",ax=ax,c=\"yellow\",zorder=-1)\n",
    "\n",
    "ax.legend([r\"$F(\\phi)$ estimate\",r\"deposited bias\",r\"$F(\\psi)$ estimate\"])   \n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$(\\phi,\\psi)$\")\n",
    "ax.set_ylabel(\"FES [Kj/mol]\")\n",
    "plt.tight_layout()\n",
    "fig.savefig(folder+\"images/\"+\"FreeEnergy_notW.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"opes.bias\"] -= np.max(data[\"opes.bias\"])\n",
    "data[:].plot.scatter(x=\"time\",y=\"opes.bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = load_dataframe(folder+\"COLVAR\")\n",
    "#data = data[data[\"time\"]>20000]\n",
    "#data = data[data[\"opes.bias\"]>-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#''' compare different set up for rescaled time\n",
    "fig1,axs1 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig2,axs2 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig3,axs3 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig4,axs4 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig5,axs5 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig6,axs6 = plt.subplots(1,3,figsize=(25,4))\n",
    "fig7,axs7 = plt.subplots(1,3,figsize=(25,6))\n",
    "fig8,axs8 = plt.subplots(1,3,figsize=(25,4))\n",
    "    \n",
    "X = data.filter(regex='^d[^a-z]').values\n",
    "# rescaled as must be\n",
    "logweight = data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "t = data['time'].values\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "axs1[0].plot(t,np.exp(logweight))\n",
    "axs1[0].set_title(\"(w,t) w\")\n",
    "axs2[0].plot(t,tprime)\n",
    "axs2[0].set_title(\"(t',t) w\")\n",
    "axs3[0].plot(t[1:],tprime[1:]/t[1:])\n",
    "axs3[0].set_title(\"(t'/t, t) w\")\n",
    "axs5[0].scatter(tprime[:1000],data[\"phi\"].to_numpy()[:1000])\n",
    "axs5[0].set_title(\"(t',phi)\")\n",
    "deltatprime = [tprime[i+1]-tprime[i] for i in range(len(tprime)-1)]\n",
    "axs6[0].scatter(t[1:],deltatprime)\n",
    "axs6[0].set_title(\"(t,deltat')\")\n",
    "bins = np.logspace(-8,1)\n",
    "hist,edges,patches = axs7[0].hist(deltatprime,bins)\n",
    "print(edges[0],edges[-1])\n",
    "print(np.max(hist))\n",
    "axs7[0].set_title(r\"Histogram of $\\Delta t$' (1)\")\n",
    "axs7[0].set_xscale(\"log\")\n",
    "axs7[0].set_yscale(\"log\")\n",
    "axs7[0].set_xlabel(\"Deltatprime\")\n",
    "axs7[0].set_ylabel(\"Counts\")\n",
    "deltaprime = deltatprime.insert(0,0)\n",
    "data[\"deltatprime\"] = deltatprime\n",
    "data.plot.scatter(x=\"phi\",y=\"psi\",c=\"deltatprime\",s=1,cmap=\"fessa\",ax=axs8[0])\n",
    "\n",
    "# rescaled as Michele wants\n",
    "logweight -= max(logweight)\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "axs1[1].plot(t,np.exp(logweight))\n",
    "axs1[1].set_title(\"(w,t) w-max()\")\n",
    "axs2[1].plot(t,tprime)\n",
    "axs2[1].set_title(\"(t',t) w-max()\")\n",
    "axs3[1].plot(t[1:],tprime[1:]/t[1:])\n",
    "axs3[1].set_title(\"(t'/t,t) w-max()\")\n",
    "axs5[1].scatter(tprime[:1000],data[\"phi\"].to_numpy()[:1000])\n",
    "axs5[1].set_title(\"(t',phi) w-max()\")\n",
    "deltatprime = [tprime[i+1]-tprime[i] for i in range(len(tprime)-1)]\n",
    "axs6[1].scatter(t[1:],deltatprime)\n",
    "axs6[1].set_title(\"(t,deltat') w-max()\")\n",
    "bins = np.logspace(-9,1.5)\n",
    "hist,edges,patches = axs7[1].hist(deltatprime,bins)\n",
    "print(np.max(hist))\n",
    "axs7[1].set_title(r\"Histogram of $\\Delta t$' (1)\")\n",
    "axs7[1].set_xscale(\"log\")\n",
    "axs7[1].set_yscale(\"log\")\n",
    "axs7[1].set_xlabel(\"Deltatprime\")\n",
    "axs7[1].set_ylabel(\"Counts\")\n",
    "deltaprime = deltatprime.insert(0,0)\n",
    "data[\"deltatprime\"] = deltatprime\n",
    "data.plot.scatter(x=\"phi\",y=\"psi\",c=\"deltatprime\",s=1,cmap=\"fessa\",ax=axs8[1])\n",
    "\n",
    "# rescaled as I want\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(np.min(logweight))\n",
    "logweight *= sim_parameters[\"beta\"]\n",
    "logweight /= np.abs(np.min(logweight))\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "axs1[2].plot(t,np.exp(logweight))\n",
    "axs1[2].set_title(\"(w,t) (w-max())/np.abs(min)\")\n",
    "axs2[2].plot(t,tprime)\n",
    "axs2[2].set_title(\"(t',t) (w-max())/np.abs(min)\")\n",
    "axs3[2].plot(t[1:],tprime[1:]/t[1:])\n",
    "axs3[2].set_title(\"(t'/t,t) (w-max())/np.abs(min)\")\n",
    "axs5[2].scatter(tprime[:1000],data[\"phi\"].to_numpy()[:1000])\n",
    "axs5[2].set_title(\"(t',phi) (w-max())/np.abs(min)\")\n",
    "deltatprime = [tprime[i+1]-tprime[i] for i in range(len(tprime)-1)]\n",
    "axs6[2].scatter(t[1:],deltatprime)\n",
    "axs6[2].set_title(\"(t,deltat') (w-max())/np.abs(min)\")\n",
    "bins = np.logspace(-5,0.1)\n",
    "hist,edges,patches = axs7[2].hist(deltatprime,bins)\n",
    "print(np.max(hist))\n",
    "axs7[2].set_title(r\"Histogram of $\\Delta t$' (1)\")\n",
    "axs7[2].set_xscale(\"log\")\n",
    "axs7[2].set_yscale(\"log\")\n",
    "axs7[2].set_xlabel(\"Deltatprime\")\n",
    "axs7[2].set_ylabel(\"Counts\")\n",
    "deltaprime = deltatprime.insert(0,0)\n",
    "data[\"deltatprime\"] = deltatprime\n",
    "data.plot.scatter(x=\"phi\",y=\"psi\",c=\"deltatprime\",s=1,cmap=\"fessa\",ax=axs8[2])\n",
    "\n",
    "#-- trajectories in phi / psi --#\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "for i in range(3):\n",
    "    data.plot.scatter(y=\"psi\",x=\"phi\",ax=axs4[i])\n",
    "    c = axs4[i].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "        norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    "    )\n",
    "    c.clabel()\n",
    "    axs4[i].grid()\n",
    "    axs4[i].set_xlabel(r\"$\\phi$\")\n",
    "    axs4[i].set_ylabel(r\"$\\psi$\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig1.savefig(folder+\"images/\"+\"t_vs_w.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "fig2.savefig(folder+\"images/\"+\"t_vs_tprime.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "fig3.savefig(folder+\"images/\"+\"tprime:t_vs_t.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "fig6.savefig(folder+\"images/\"+\"t_vs_deltatprime.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "fig7.savefig(folder+\"images/\"+\"histdeltatprime.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "fig8.savefig(folder+\"images/\"+\"Scatterdeltatprime.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig,axs1 = plt.subplots(1,3,figsize=(20,4))\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "t = data['time'].values\n",
    "X = data.filter(regex='^d[^a-z]').values\n",
    "logweight = data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "x = data[\"phi\"].values\n",
    "#-- without minus max --#\n",
    "autocorr = np.empty(0)\n",
    "N = 100\n",
    "lags = np.linspace(0,10,N)\n",
    "for lag in lags:\n",
    "    res = my_autocorrelation_python(x,lag=lag,weight=np.exp(logweight),time=t, tprime=tprime)\n",
    "    autocorr = np.append(autocorr,res)\n",
    "axs1[0].plot(lags,autocorr)\n",
    "axs1[0].set_title(\"(t,w)\")\n",
    "#-- with minus max --#\n",
    "autocorr = np.empty(0)\n",
    "logweight -= max(logweight)\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "for lag in lags:\n",
    "    res = my_autocorrelation_python(x,lag=lag,weight=np.exp(logweight),time=t, tprime=tprime)\n",
    "    autocorr = np.append(autocorr,res)\n",
    "axs1[1].plot(lags,autocorr)\n",
    "axs1[1].set_title(\"(t,w) w-max() \")\n",
    "#-- with minus max and / np.abs(min)--#\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "logweight /= np.abs(np.min(logweight))\n",
    "autocorr = np.empty(0)\n",
    "logweight *= sim_parameters[\"beta\"]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "for lag in lags:\n",
    "    res = my_autocorrelation_python(x,lag=lag,weight=np.exp(logweight),time=t, tprime=tprime)\n",
    "    autocorr = np.append(autocorr,res)\n",
    "axs1[2].plot(lags,autocorr)\n",
    "axs1[2].set_title(\"(t,w) (w-max())/np.abs(min)\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_names = data.filter(regex='^p').columns.values\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(8,4),sharey=True)\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[desc].plot.hist(bins=50,alpha=1,ax=ax,legend=False,grid=True,histtype='step',linewidth=2,density=True)\n",
    "    data[desc].plot.hist(bins=50,alpha=0.5,ax=ax,legend=False,grid=True,color=\"grey\",density=True)\n",
    "    ax.set_title(desc)\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "for ax,desc in zip(axs.flatten(),descriptors_names):\n",
    "    data[::1].plot.scatter(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,linewidth=2,marker=\"^\")\n",
    "    #data[::100].plot.line(x=\"time\",y=desc,alpha=1,ax=ax,legend=False,grid=True,color=\"grey\")\n",
    "    ax.set_title(desc)\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"phi_psi.png\",transparent=False,facecolor=\"white\",dpi=300)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep TICA Analysis  \n",
    "Qui analizzo con la Deeptica la simulazione biased.  \n",
    "Lo farò utilizzando 4 diversi tprime per il tempo riscalato: \n",
    "1. senza usare il tempo riscalato \n",
    "2. usando il vero e proprio tempo riscalato con tprime = dt * exp(beta*logweights)\n",
    "3. come farebbe michele con tprime = dt * exp(beta*logweights-max(beta*logweights))\n",
    "4. come farei io con logweights -= max(logweights); logweights /= np.abs(np.min(logweights)); logweights \\*= beta, tprime = dt * exp(logweights)\n",
    "\n",
    "Results: \n",
    "Per tempi molti grandi nessuno degli algoritmi lavora bene. Per tempi piccoli, sulla scala del tempo di stride, lavora bene *1* e *4*, su tempi molto piccoli nessuno lavora bene.  \n",
    "Facendo a batches tra 1, 5 con 5 valori:   \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "data = load_dataframe(folder+\"COLVAR\")[:]\n",
    "size = len(data)\n",
    "min_lag,max_lag = 1,2 \n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "shuffle = False # if shuffle the data between batches\n",
    "#-- train_datasets and valid_datasets list, it will be filled with new data every iteration\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# torch seed \n",
    "torch.manual_seed(21)\n",
    "\n",
    "descriptors_names = data.filter(regex='^d[^a-z]').columns.values\n",
    "\n",
    "#-- TRAINING PARAMETERS --#\n",
    "n_output = 2 # 2 non linear combination of the descriptors  \n",
    "n_input = len(descriptors_names) # can change..\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,30,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':1000,\n",
    "              'batchsize': -1, #---> è da fare sul train loder and valid loader\n",
    "              'es_patience':1000,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "\n",
    "# how many data in single batch, batchsize\n",
    "n_train = int( size*train_parameters[\"trainsize\"] )\n",
    "n_valid = int( size*(1-train_parameters[\"trainsize\"])-int(10*max_lag) )\n",
    "print(\"training samples: \",n_train, \"\\t validation samples\", n_valid)\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = \"cpu\"\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "train_parameters['num_epochs'] = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(torch.get_num_threads())\n",
    "#torch.set_num_threads(16)\n",
    "#print(torch.get_num_interop_threads())\n",
    "#torch.set_num_interop_threads(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=lag,interval=[0,n_train+n_valid])\n",
    "    print(len(dataset))\n",
    "    # save correlated couples and weights\n",
    "    x_t,x_lag,w_t,w_lag = np.array(dataset[:][0]),np.array(dataset[:][1]),np.array(dataset[:][2]),np.array(dataset[:][3])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_time_lagged_dataset(X,t=t,lag_time=1000)\n",
    "print(len(dataset))\n",
    "# save correlated couples and weights\n",
    "x_t,x_lag,w_t,w_lag = np.array(dataset[:][0]),np.array(dataset[:][1]),np.array(dataset[:][2]),np.array(dataset[:][3])\n",
    "print(len(x_t))\n",
    "indeces_t_1 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_t.T[0] ]\n",
    "indeces_lag_1 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_lag.T[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"red\")\n",
    "data.iloc[indeces_lag_1].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"blue\",alpha=0.5)\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_1][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_1][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_1][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$Energy$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1][descriptors_names].plot.hist(ax=ax,color=\"red\",density=True,histtype='step',linewidth=2,legend=False)\n",
    "data.iloc[indeces_lag_1][descriptors_names].plot.hist(ax=ax,histtype='step',density=True,color=\"blue\",linewidth=2,legend=False)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "#time series\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_1].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_1].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_1].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6),sharey=True)\n",
    "\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"fessa\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"fessa\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"cv_t.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,30,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':5e-4,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':500,\n",
    "              'batchsize': -1, #---> è da fare sul train loder and valid loader\n",
    "              'es_patience':100,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "\n",
    "# evaluate tprime\n",
    "logweight = data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "X = data[descriptors_names].to_numpy()\n",
    "#lags = [6]\n",
    "min_lag,max_lag = 1,1#0.01,25\n",
    "n = 1#50 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcvs.utils.data import create_time_lagged_dataset_new\n",
    "\n",
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset_new(X,t=t,lag_time=lag,tprime=tprime,logweights=logweight,interval=[0,n_train+n_valid])\n",
    "    print(len(dataset))\n",
    "    x_t,x_lag,w_t,w_lag = np.array(dataset[:][0]),np.array(dataset[:][1]),np.array(dataset[:][2]),np.array(dataset[:][3])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    #train_data = Subset(dataset,np.arange(0,n_valid) )\n",
    "    #valid_data = Subset(dataset,np.arange(n_valid,n_train+n_valid) )\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_t))\n",
    "indeces_t_2 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_t.T[0] ]\n",
    "indeces_lag_2 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_lag.T[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_2].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"red\")\n",
    "data.iloc[indeces_lag_2].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"blue\",alpha=0.5)\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_2][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_2][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_2][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_2][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_2][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_2][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$Energy$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_2][descriptors_names].plot.hist(ax=ax,color=\"red\",density=True,histtype='step',linewidth=2,legend=False)\n",
    "data.iloc[indeces_lag_2][descriptors_names].plot.hist(ax=ax,histtype='step',density=True,color=\"blue\",linewidth=2,legend=False)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "#time series\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "data.iloc[indeces_t_2].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_2].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(16,8))\n",
    "data.iloc[indeces_t_2].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_2].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[descriptors_names].to_numpy()\n",
    "\n",
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"viridis\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"viridis\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"cv_tprime_w.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "\n",
    "torch.manual_seed(21)\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,30,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':400,\n",
    "              'batchsize': -1, #---> è da fare sul train loder and valid loader\n",
    "              'es_patience':100,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }\n",
    "\n",
    "# evaluate tprime\n",
    "logweight =  data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]-np.max(data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"] )\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "#lags = [6]\n",
    "min_lag,max_lag = 1,1#0.01,25\n",
    "n = 1#50 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "\n",
    "min_lag,max_lag = 1,1#0.001,1\n",
    "n = 1#50 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset_new(X,t=t,lag_time=lag,tprime=tprime,logweights=logweight,interval=[0,n_train+n_valid])\n",
    "    x_t,x_lag,w_t,w_lag = np.array(dataset[:][0]),np.array(dataset[:][1]),np.array(dataset[:][2]),np.array(dataset[:][3])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_t))\n",
    "indeces_t_3 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_t.T[0] ]\n",
    "indeces_lag_3 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_lag.T[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"red\")\n",
    "data.iloc[indeces_lag_3].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"blue\",alpha=0.5)\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_3][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_3][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_3][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$Energy$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3][descriptors_names].plot.hist(ax=ax,color=\"red\",density=True,histtype='step',linewidth=2,legend=False)\n",
    "data.iloc[indeces_lag_3][descriptors_names].plot.hist(ax=ax,histtype='step',density=True,color=\"blue\",linewidth=2,legend=False)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "#time series\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_3].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_3].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_3].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[descriptors_names].to_numpy()\n",
    "\n",
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"viridis\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"viridis\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"cv_tprime_w-max.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate tprime\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight *= sim_parameters[\"beta\"]\n",
    "logweight /= np.abs(min(logweight))\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "min_lag,max_lag = 1,1\n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]', # can change during simulation\n",
    "              'nodes':[n_input,30,30,n_output],\n",
    "              'activ_type': 'tanh',#'relu','selu','tanh'\n",
    "              'lag_time':10, \n",
    "              'loss_type': 'sum', \n",
    "              'n_eig': n_output,\n",
    "              'trainsize':0.7, \n",
    "              'lrate':1e-3,\n",
    "              'l2_reg':0.,\n",
    "              'num_epochs':500,\n",
    "              'batchsize': -1, #---> è da fare sul train loder and valid loader\n",
    "              'es_patience':10,\n",
    "              'es_consecutive':True,\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              'log_every':50,\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets = []\n",
    "valid_datasets = []\n",
    "# create time lagged dataset with different lag times\n",
    "for lag in lags:\n",
    "    #random split\n",
    "    # TensorDataset (x_t,x_lag,w_t,w_lag)\n",
    "    dataset = create_time_lagged_dataset(X,t=t,lag_time=np.round(lag,3),tprime=tprime,logweights=logweight,interval=[0,n_train+n_valid])\n",
    "    x_t,x_lag,w_t,w_lag = np.array(dataset[:][0]),np.array(dataset[:][1]),np.array(dataset[:][2]),np.array(dataset[:][3])\n",
    "    train_data, valid_data = random_split(dataset,[n_train,n_valid])\n",
    "    train_datasets.append(train_data)\n",
    "    valid_datasets.append(valid_data)\n",
    "\n",
    "train_loader = FastTensorDataLoader(train_datasets, batch_size=n_train,shuffle=shuffle)\n",
    "valid_loader = FastTensorDataLoader(valid_datasets, batch_size=n_valid,shuffle=shuffle)\n",
    "\n",
    "#-- TRAIN --#\n",
    "# MODEL\n",
    "model = DeepTICA_CV(train_parameters['nodes'],activation=train_parameters['activ_type'],gaussian_random_initialization=True)\n",
    "model.to(device)\n",
    "# OPTIMIZER (Adam)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=train_parameters['lrate'], weight_decay=train_parameters['l2_reg'])\n",
    "# lrscheduler\n",
    "#model.set_LRScheduler(opt,min_lr=5e-5)\n",
    "model.set_optimizer(opt)\n",
    "if valid_loader is not None:\n",
    "    # EarlyStopping\n",
    "    model.set_earlystopping(patience=train_parameters['es_patience'],\n",
    "                            min_delta=0.005,consecutive=train_parameters['es_consecutive'], save_best_model=True, log=False) \n",
    "# TRAIN\n",
    "model.fit(train_loader=train_loader,valid_loader=valid_loader,\n",
    "    standardize_inputs=train_parameters['standardize_inputs'],\n",
    "    standardize_outputs=train_parameters['standardize_outputs'],\n",
    "    loss_type=train_parameters['loss_type'],\n",
    "    n_eig=train_parameters['n_eig'],\n",
    "    nepochs=train_parameters['num_epochs'],\n",
    "    info=False, log_every=train_parameters['log_every'])\n",
    "#-- move the model back to cpu for convenience --#\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_t))\n",
    "indeces_t_4 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_t.T[0] ]\n",
    "indeces_lag_4 = [ data.index[ np.abs(data[descriptors_names].to_numpy().T[0]-el) < 1e-6 ][0] for el in x_lag.T[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"red\")\n",
    "data.iloc[indeces_lag_4].plot.scatter(x=\"phi\",y=\"psi\",ax=ax,c=\"blue\",alpha=0.5)\n",
    "\n",
    "#histograms phi,psi,energy\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_4][\"phi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_4][\"psi\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$\\psi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"red\")\n",
    "data.iloc[indeces_lag_4][\"ene\"].plot.hist(density=False,histtype='step',linewidth=2,ax=ax,bins=100,color=\"blue\",alpha=0.5)\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_ylabel(r\"$Energy$\")\n",
    "\n",
    "#histograms descriptors\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4][descriptors_names].plot.hist(ax=ax,color=\"red\",density=True,histtype='step',linewidth=2,legend=False)\n",
    "data.iloc[indeces_lag_4][descriptors_names].plot.hist(ax=ax,histtype='step',density=True,color=\"blue\",linewidth=2,legend=False)\n",
    "ax.set_yscale(\"log\")\n",
    "\n",
    "#time series\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_4].plot.scatter(x=\"time\",y=\"phi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\phi$\")\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,8))\n",
    "data.iloc[indeces_t_4].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"red\")\n",
    "data.iloc[indeces_lag_4].plot.scatter(x=\"time\",y=\"psi\",ax=ax,color=\"blue\",marker=\"^\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_lossfunction(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"fessa\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"fessa\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"cv_tprime_w-max_divmin.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TICA Analysis  \n",
    "Ripeto le stesse analisi di cui sopra ma con la TICA, per capire se la rete può portare ad artefatti   \n",
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "\n",
    "min_lag,max_lag = 1,10 \n",
    "n = 1 # how many lag times between min and max lag\n",
    "lags = np.linspace(min_lag,max_lag,n) #-- how many batches for the train and valid set of a single simulation\n",
    "print(lags)\n",
    "torch.manual_seed(21)\n",
    "\n",
    "descriptors_names = data.filter(regex='^d[^a-z]').columns.values\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "model.fit_new(X, t, lag=1)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6),sharey=True)\n",
    "\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"fessa\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"fessa\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"TICAcv_t.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")[::5]\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "\n",
    "# evaluate tprime\n",
    "logweight = data[\"opes.bias\"].to_numpy()*sim_parameters[\"beta\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "#lags = [6]\n",
    "min_lag,max_lag = 20,1\n",
    "n = 1\n",
    "lags = np.linspace(min_lag,max_lag,n) \n",
    "print(lags)\n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "model.fit_new(X, t, lag=5, logweights=logweight,tprime=tprime)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"viridis\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"viridis\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"TICAcv_tprime_w.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "Numerical issues with TICA and solve the tica problem. Inversion of C(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")[::5]\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "\n",
    "# evaluate tprime\n",
    "logweight =  (data[\"opes.bias\"].to_numpy()-np.max(data[\"opes.bias\"].to_numpy()) ) *sim_parameters[\"beta\"]\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "model.fit_new(X, t, lag=100, logweights=logweight,tprime=tprime)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"viridis\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"viridis\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"TICAcv_tprime_w-max.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "t = data['time'].values\n",
    "X = data[descriptors_names].values\n",
    "\n",
    "# evaluate tprime\n",
    "logweight = data[\"opes.bias\"].to_numpy()-max(data[\"opes.bias\"].to_numpy())\n",
    "#logweight /= np.abs(min(logweight))\n",
    "logweight *= sim_parameters[\"beta\"]\n",
    "logweight /= np.abs(min(logweight))\n",
    "dt = t[1]-t[0]\n",
    "tprime = dt * np.cumsum(np.exp(logweight))\n",
    "min_lag,max_lag = 1,1\n",
    "n = 1 \n",
    "lags = np.linspace(min_lag,max_lag,n) \n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "model.fit_new(X, t, lag=min_lag, logweights=logweight,tprime=tprime)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "#print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot cvs #\n",
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]   \n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(12,6))\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv1\",cmap=\"fessa\",ax=ax[0])\n",
    "data.plot.hexbin(y=\"psi\",x=\"phi\",C=\"cv2\",cmap=\"fessa\",ax=ax[1])\n",
    "\n",
    "fes = np.loadtxt(\"angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax[0].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c = ax[1].contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax[0].grid()\n",
    "ax[0].set_xlabel(r\"$\\phi$\")\n",
    "ax[0].set_ylabel(r\"$\\psi$\")\n",
    "ax[0].set_title(\"Deep TICA 1\")\n",
    "ax[1].grid()\n",
    "ax[1].set_xlabel(r\"$\\phi$\")\n",
    "ax[1].set_ylabel(r\"$\\psi$\")\n",
    "ax[1].set_title(\"Deep TICA 2\")\n",
    "\n",
    "fig.savefig(folder+\"images/\"+\"TICAcv_tprime_w-max_divmin.png\",transparent=False,facecolor=\"white\",dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\Delta F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#-- each step is 1ps --#\n",
    "data = load_dataframe(folder+\"COLVAR\").filter(regex=\"^phi\").to_numpy()[:]\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0][:]\n",
    "logweight= (logweight-np.max(logweight))*sim_parameters[\"beta\"]\n",
    "s = data[:]\n",
    "weight = np.exp(logweight[:])\n",
    "fes,grid,bounds,error = compute_fes(s, weights=weight,\n",
    "                                    temp=sim_parameters[\"temp\"],\n",
    "                                    kbt=sim_parameters[\"kbt\"],\n",
    "                                    blocks=2,\n",
    "                                    bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                    plot=False)\n",
    "ind1 = (grid<0) \n",
    "ind2 = (grid>0) \n",
    "grid1 = grid[ ind1 ]\n",
    "grid2 = grid[ ind2 ] \n",
    "I1 = integrate.trapz(np.exp(-fes[ind1]*sim_parameters[\"beta\"]), grid1)\n",
    "I2 = integrate.trapz(np.exp(-fes[ind2]*sim_parameters[\"beta\"]), grid2)\n",
    "    \n",
    "res = (1/sim_parameters[\"beta\"])*np.log(I1/I2)\n",
    "print(res)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#-- each step is 1ps --#\n",
    "#-- we are interested in the first 10 ns --#\n",
    "last = 1*1000*10 #last ns\n",
    "data = load_dataframe(folder+\"COLVAR\").filter(regex=\"^phi\").to_numpy()[:last]\n",
    "logweight= np.transpose( load_dataframe(folder+\"COLVAR\").filter(regex=\"^opes.bias$\").to_numpy() )[0][:last]\n",
    "logweight= (logweight-np.max(logweight))*sim_parameters[\"beta\"]\n",
    "#-- with CLEAR set to 1000 I perform the estimation every ns --#\n",
    "CLEAR=100\n",
    "\n",
    "deltaf = np.empty(0)\n",
    "for el in np.arange(CLEAR,len(data)+CLEAR,CLEAR):\n",
    "    s = data[:el]\n",
    "    weight = np.exp(logweight[:el])\n",
    "    fes,grid,bounds,error = compute_fes(s, weights=weight,\n",
    "                                        temp=sim_parameters[\"temp\"],\n",
    "                                        kbt=sim_parameters[\"kbt\"],\n",
    "                                        blocks=2,\n",
    "                                        bandwidth=sim_parameters[\"bandwidth\"],scale_by='range',\n",
    "                                        plot=False)\n",
    "    ind1 = (grid<0) \n",
    "    ind2 = (grid>0) \n",
    "    grid1 = grid[ ind1 ]\n",
    "    grid2 = grid[ ind2 ] \n",
    "    I1 = integrate.trapz(np.exp(-fes[ind1]*sim_parameters[\"beta\"]), grid1)\n",
    "    I2 = integrate.trapz(np.exp(-fes[ind2]*sim_parameters[\"beta\"]), grid2)\n",
    "    \n",
    "    deltaf = np.append(deltaf,(1/sim_parameters[\"beta\"])*np.log(I1/I2))\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,6))\n",
    "ax.plot(np.arange(len(deltaf)),deltaf,label=\"Estimate\")\n",
    "res = np.full(len(deltaf),res)\n",
    "err = np.full(len(deltaf),0.2*kb*sim_parameters[\"temp\"])\n",
    "ax.plot(np.arange(len(deltaf)),res,linestyle='--',linewidth=3,color=\"g\",label=\"ref\")\n",
    "ax.fill_between(np.arange(len(deltaf)) , res-err, res+err , color=\"r\",zorder=0,alpha=0.3)\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$t$ [ps$\\times$\"+str(CLEAR)+\"]\")\n",
    "ax.set_ylabel(r\"$\\Delta F$ [Kj/mol]\")\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('mlcvs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "34f06b9f9681e9a7231f3100f6e351611d3f9f188d680707206d70c247429f78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
