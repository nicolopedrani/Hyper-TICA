{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import needed modules and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- useful python script to compute the TICA cvs --#\n",
    "from utils import *\n",
    "\n",
    "#-- to not visualize warnings --#\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb=0.008314\n",
    "#-- SIMULATION PARAMETERS --#\n",
    "sim_parameters = {\n",
    "    'temp':300, \n",
    "    'beta': 1./(300*kb),\n",
    "    'kbt': None,\n",
    "    #-- parameters to compute the fes --#\n",
    "    'blocks':2,\n",
    "    'bandwidth': 0.02,\n",
    "    'plot_max_fes' :70,\n",
    "}\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare input files for plumed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"unbias_A/\"\n",
    "Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(folder+\"plumed.dat\",\"w\") as file:\n",
    "    print(\"\"\"\n",
    "# vim:ft=plumed\n",
    "\n",
    "MOLINFO STRUCTURE=input.ala2.pdb\n",
    "phi: TORSION ATOMS=@phi-2\n",
    "psi: TORSION ATOMS=@psi-2\n",
    "ene: ENERGY\n",
    "\n",
    "INCLUDE FILE=plumed_descriptors.data\n",
    "\n",
    "PRINT FMT=%g STRIDE=500 FILE=COLVAR ARG=*\n",
    "\n",
    "ENDPLUMED\n",
    "\"\"\",file=file)\n",
    "\n",
    "#-- run gromacs --#\n",
    "#execute(\"cp ../script/input.* ../script/plumed_descriptors.data \"+folder,folder=\".\")\n",
    "#execute(\"./run_gromacs.sh\",folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(10,8))\n",
    "load_dataframe(folder+\"COLVAR\").plot.scatter(y=\"psi\",x=\"phi\",ax=ax)\n",
    "\n",
    "fes = np.loadtxt(\"../angles/fes.txt\",delimiter=\" \")\n",
    "grid0 = np.loadtxt(\"../angles/grid0.txt\",delimiter=\" \")\n",
    "grid1 = np.loadtxt(\"../angles/grid1.txt\",delimiter=\" \")\n",
    "bounds = np.arange(0, 60, 5.)\n",
    "c = ax.contour(grid0, grid1, fes, bounds, linewidths=3,cmap=\"gray\",linestyles=\"dashed\",\n",
    "    norm = mpl.colors.BoundaryNorm(bounds, ncolors=len(bounds)-1, clip=False), label=\"FES [Kj/mol]\",\n",
    ")\n",
    "c.clabel()\n",
    "ax.grid()\n",
    "ax.set_xlabel(r\"$\\phi$\")\n",
    "ax.set_ylabel(r\"$\\psi$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- TRAINING PARAMETERS --#\n",
    "train_parameters = {\n",
    "              'descriptors': '^d[^a-z]',\n",
    "              'lag_time':1,#1,4,8\n",
    "              'standardize_outputs':True,\n",
    "              'standardize_inputs': True,\n",
    "              #if reweight the timescale\n",
    "              \"reweighting\": False,\n",
    "              \"step\": 1 #se prendo tutti i valori fallisce il cholesky decomposition.. issue con pytorch\n",
    "              }\n",
    "#--------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimation of the lag time with maximum gap, with TICA applied on the Descriptors\n",
    "data = load_dataframe(folder+\"COLVAR\")\n",
    "data = data[::train_parameters[\"step\"]]\n",
    "X, names, t = data.filter(regex='^d[^a-z]').values, data.filter(regex='^d[^a-z]').columns.values, data['time'].values\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "lags = np.linspace(1,10,10)\n",
    "timescale = np.empty(len(lags))\n",
    "\n",
    "for i,lag in enumerate(lags):\n",
    "    # TRAIN\n",
    "    model.fit(X, t, lag=lag)\n",
    "    #-- move the model back to cpu for convenience --# \n",
    "    timescale[i] = model.tica.evals_.detach().cpu().numpy()[0]-model.tica.evals_.detach().cpu().numpy()[1]\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lags,timescale)\n",
    "#print(timescale)\n",
    "#print(lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepTICA Analysis and Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(21)\n",
    "X, names, t = data.filter(regex='^d[^a-z]').values, data.filter(regex='^d[^a-z]').columns.values, data['time'].values\n",
    "\n",
    "# DEVICE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# MODEL\n",
    "model = TICA_CV(n_features=X.shape[1])\n",
    "model.to(device)\n",
    "\n",
    "# TRAIN\n",
    "model.fit(X, t, lag=lag)\n",
    "\n",
    "#-- move the model back to cpu for convenience --# \n",
    "model.to('cpu')\n",
    "\n",
    "#-- print some useful results --#\n",
    "print(\"timescales: \",model.tica.timescales(train_parameters[\"lag_time\"]).detach().cpu().numpy()) \n",
    "print(\"eigenvalues: \",model.tica.evals_.detach().cpu().numpy())\n",
    "print(\"gap: \", model.tica.evals_.detach().cpu().numpy()[0]-model.tica.evals_.detach().cpu().numpy()[1])\n",
    "\n",
    "model.set_params({\"feature_names\": names})\n",
    "print( model.plumed_input().readlines()[:2] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding to data the cvs values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors_names = data.filter(regex='^d[^a-z]').columns.values\n",
    "data_complete = load_dataframe(\"../angles/COLVAR\")\n",
    "X_complete = data_complete[descriptors_names].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"cv1\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[0]\n",
    "data[\"cv2\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[1]\n",
    "data[\"cv3\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[2]\n",
    "data[\"cv4\"] = np.transpose(model(torch.Tensor(X)).detach().cpu().numpy())[3]\n",
    "data_complete[\"cv1\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[0]\n",
    "data_complete[\"cv2\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[1]\n",
    "data_complete[\"cv3\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[2]\n",
    "data_complete[\"cv4\"] = np.transpose(model(torch.Tensor(X_complete)).detach().cpu().numpy())[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,4,figsize=(18,6),sharey=True)\n",
    "data.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"b\",label=\"cv1 data\")\n",
    "data.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"b\",label=\"cv2 data\")\n",
    "data.plot.hist(y=\"cv3\",bins=20,ax=axs[2],density=True,color=\"b\",label=\"cv3 data\")\n",
    "data.plot.hist(y=\"cv4\",bins=20,ax=axs[3],density=True,color=\"b\",label=\"cv4 data\")\n",
    "data_complete.plot.hist(y=\"cv1\",bins=20,ax=axs[0],density=True,color=\"r\",label=\"cv1 data complete\")\n",
    "data_complete.plot.hist(y=\"cv2\",bins=20,ax=axs[1],density=True,color=\"r\",label=\"cv2 data complete\")\n",
    "data_complete.plot.hist(y=\"cv3\",bins=20,ax=axs[2],density=True,color=\"r\",label=\"cv3 data complete\")\n",
    "data_complete.plot.hist(y=\"cv4\",bins=20,ax=axs[3],density=True,color=\"r\",label=\"cv4 data complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the correlation (*Pearson* correlation ,which simply means normed correlation) of the Deep-TICA cvs with the descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(4,1,figsize=(16,24),sharex=True)\n",
    "for k,cv in enumerate([\"cv1\",\"cv2\",\"cv3\",\"cv4\"]):\n",
    "    cols = [cv]\n",
    "    cols.extend(data.filter(regex=train_parameters[\"descriptors\"]).columns)\n",
    "    corr = data[cols].corr(method='pearson')\n",
    "    corr[cv].drop(cv).plot(kind='bar', ax=axs[k], rot=35, color=\"b\",label=r\"$C(tica|desc)$\")\n",
    "    axs[k].set_title('Correlation with TICA '+str(k+1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "for k,ax in enumerate(axs):\n",
    "    data.plot.scatter(y=\"psi\",x=\"phi\",c=\"cv\"+str(k+1),cmap=\"Set1\",ax=ax)\n",
    "    ax.set_xlabel(r\"$\\phi$\")\n",
    "    ax.set_ylabel(r\"$\\psi$\")\n",
    "    ax.set_title('TICA '+str(k+1))\n",
    "plt.tight_layout()\n",
    "fig,axs = plt.subplots(1,4,figsize=(18,6))\n",
    "for k,ax in enumerate(axs):\n",
    "    data_complete.plot.scatter(y=\"psi\",x=\"phi\",c=\"cv\"+str(k+1),cmap=\"Set1\",ax=ax)\n",
    "    ax.set_xlabel(r\"$\\phi$\")\n",
    "    ax.set_ylabel(r\"$\\psi$\")\n",
    "    ax.set_title('TICA '+str(k+1))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogonality  \n",
    "We said that the **ICs** must satisfy two conditions. The first one is that they are uncorrelated, which means that $\\int d \\vec x \\psi_1(\\vec x) \\psi_2(\\vec x) e^{-\\beta U(\\vec x)} = 0$.  \n",
    "But their scalar product on the data will lead to a slightly different result, in this case approximately $0$, but not perfectly $0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boltzmann_product(model,model,X,j=0,k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This results reflects the fact that we have enforce the symmetrization of $C(\\tau)$  \n",
    "then one can enforce the orthogonality on the data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
